"""
visualisations_multimodales.py
SYST√àME COMPLET DE VISUALISATIONS POUR DONN√âES MULTIMODALES
CSV + Images - Exploration et Analyse

Visualisations cr√©√©es :
1. CSV : Distributions, corr√©lations, qualit√©
2. Images : Histogrammes, mosa√Øques, stats
3. Fusion : Relations CSV ‚Üî Images
4. Comparaisons : Avant/Apr√®s

Auteur: TIA Ange Jules-Rihem ben Maouia
Date: D√©cembre 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from pathlib import Path
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration
BASE_DIR = Path(".")
CLEANED_CSV = BASE_DIR / "data" / "cleaned" / "csv"
CLEANED_IMAGES = BASE_DIR / "data" / "cleaned" / "images"
FEATURES_DIR = BASE_DIR / "data" / "cleaned" / "features"
FIGURES_DIR = BASE_DIR / "presentation" / "figures"
REPORTS_DIR = BASE_DIR / "reports"

FIGURES_DIR.mkdir(parents=True, exist_ok=True)

# Style matplotlib
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*80)
print("üìä G√âN√âRATION VISUALISATIONS MULTIMODALES")
print("="*80 + "\n")

visualizations_created = []

# ==========================================
# 1. VISUALISATIONS CSV
# ==========================================

print("üìà Partie 1: Visualisations CSV")
print("-" * 80)

# Charger les CSV
csv_files = list(CLEANED_CSV.glob("*.csv")) if CLEANED_CSV.exists() else []
all_data = {}

for csv_file in csv_files:
    df = pd.read_csv(csv_file)
    all_data[csv_file.stem] = df

if all_data:
    # Viz 1: Distribution des classes (pathology)
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Distribution des Classes par Dataset', fontsize=16, fontweight='bold')
    
    for idx, (name, df) in enumerate(list(all_data.items())[:4]):
        ax = axes[idx // 2, idx % 2]
        
        if 'pathology' in df.columns:
            counts = df['pathology'].value_counts()
            colors = ['#2ecc71' if 'benign' in str(x).lower() else '#e74c3c' for x in counts.index]
            
            bars = ax.bar(range(len(counts)), counts.values, color=colors, edgecolor='black', linewidth=1.5)
            ax.set_xticks(range(len(counts)))
            ax.set_xticklabels(counts.index, rotation=45, ha='right')
            ax.set_title(name[:30], fontweight='bold')
            ax.set_ylabel('Nombre de cas')
            ax.grid(axis='y', alpha=0.3)
            
            # Annotations
            for bar, val in zip(bars, counts.values):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{int(val)}\n({val/len(df)*100:.1f}%)',
                       ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    plt.tight_layout()
    fig_path = FIGURES_DIR / '01_distribution_classes.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    visualizations_created.append(str(fig_path))
    print(f"   ‚úÖ {fig_path.name}")
    plt.close()
    
    # Viz 2: Qualit√© des Donn√©es (Compl√©tude)
    fig, ax = plt.subplots(figsize=(12, 6))
    
    datasets = []
    completeness = []
    
    for name, df in all_data.items():
        datasets.append(name[:25])
        missing_pct = (df.isnull().sum().sum() / (len(df) * df.shape[1])) * 100
        completeness.append(100 - missing_pct)
    
    bars = ax.barh(datasets, completeness, color='skyblue', edgecolor='navy', linewidth=2)
    ax.set_xlabel('Compl√©tude (%)', fontweight='bold')
    ax.set_title('Qualit√© des Datasets CSV', fontsize=14, fontweight='bold')
    ax.axvline(x=95, color='green', linestyle='--', linewidth=2, label='Seuil 95%')
    ax.axvline(x=90, color='orange', linestyle='--', linewidth=2, label='Seuil 90%')
    ax.legend()
    ax.grid(axis='x', alpha=0.3)
    
    # Annotations
    for bar, val in zip(bars, completeness):
        width = bar.get_width()
        ax.text(width, bar.get_y() + bar.get_height()/2.,
               f'{val:.2f}%', ha='left', va='center', fontweight='bold', fontsize=10)
    
    plt.tight_layout()
    fig_path = FIGURES_DIR / '02_qualite_datasets.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    visualizations_created.append(str(fig_path))
    print(f"   ‚úÖ {fig_path.name}")
    plt.close()
    
    # Viz 3: Corr√©lation entre variables num√©riques (exemple avec un dataset)
    sample_df = list(all_data.values())[0]
    numeric_cols = sample_df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) > 1:
        fig, ax = plt.subplots(figsize=(10, 8))
        corr_matrix = sample_df[numeric_cols].corr()
        
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
                   center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8},
                   ax=ax)
        ax.set_title('Matrice de Corr√©lation - Variables Num√©riques', 
                    fontsize=14, fontweight='bold', pad=20)
        
        plt.tight_layout()
        fig_path = FIGURES_DIR / '03_correlation_matrix.png'
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        visualizations_created.append(str(fig_path))
        print(f"   ‚úÖ {fig_path.name}")
        plt.close()

# ==========================================
# 2. VISUALISATIONS IMAGES
# ==========================================

print(f"\nüñºÔ∏è  Partie 2: Visualisations Images")
print("-" * 80)

if CLEANED_IMAGES.exists():
    # Viz 4: Mosa√Øque d'exemples
    fig, axes = plt.subplots(4, 5, figsize=(20, 16))
    fig.suptitle('√âchantillon d\'Images Pr√©trait√©es', fontsize=16, fontweight='bold')
    
    # Collecter quelques images
    sample_images = []
    for label in ['benign', 'malignant']:
        for split in ['train', 'test']:
            img_dir = CLEANED_IMAGES / split / label
            if img_dir.exists():
                imgs = list(img_dir.glob("*.jpg"))[:5]
                for img_path in imgs:
                    sample_images.append((img_path, f"{split}_{label}"))
    
    for idx, ax in enumerate(axes.flat):
        if idx < len(sample_images):
            img_path, label = sample_images[idx]
            img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
            
            if img is not None:
                ax.imshow(img, cmap='gray')
                ax.set_title(label, fontsize=10, fontweight='bold')
                ax.axis('off')
        else:
            ax.axis('off')
    
    plt.tight_layout()
    fig_path = FIGURES_DIR / '04_mosaique_images.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    visualizations_created.append(str(fig_path))
    print(f"   ‚úÖ {fig_path.name}")
    plt.close()
    
    # Viz 5: Histogrammes d'intensit√©
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Distribution d\'Intensit√© par Classe', fontsize=16, fontweight='bold')
    
    plot_idx = 0
    for split in ['train', 'test']:
        for label in ['benign', 'malignant']:
            ax = axes[plot_idx // 2, plot_idx % 2]
            
            img_dir = CLEANED_IMAGES / split / label
            if img_dir.exists():
                all_intensities = []
                for img_path in list(img_dir.glob("*.jpg"))[:20]:
                    img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                    if img is not None:
                        all_intensities.extend(img.flatten())
                
                if all_intensities:
                    color = '#2ecc71' if label == 'benign' else '#e74c3c'
                    ax.hist(all_intensities, bins=50, color=color, alpha=0.7, edgecolor='black')
                    ax.set_title(f'{split.upper()} - {label.upper()}', fontweight='bold')
                    ax.set_xlabel('Intensit√©')
                    ax.set_ylabel('Fr√©quence')
                    ax.grid(alpha=0.3)
            
            plot_idx += 1
    
    plt.tight_layout()
    fig_path = FIGURES_DIR / '05_histogrammes_intensite.png'
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    visualizations_created.append(str(fig_path))
    print(f"   ‚úÖ {fig_path.name}")
    plt.close()

# ==========================================
# 3. VISUALISATIONS FUSION
# ==========================================

print(f"\nüîó Partie 3: Visualisations Fusion CSV ‚Üî Images")
print("-" * 80)

# Viz 6: R√©capitulatif multimodal
fig = plt.figure(figsize=(16, 10))
gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)

# Dataset sizes
ax1 = fig.add_subplot(gs[0, 0])
if all_data:
    sizes = [len(df) for df in all_data.values()]
    names = [name[:15] for name in all_data.keys()]
    ax1.bar(range(len(sizes)), sizes, color='steelblue', edgecolor='black')
    ax1.set_xticks(range(len(sizes)))
    ax1.set_xticklabels(names, rotation=45, ha='right', fontsize=9)
    ax1.set_title('Taille des Datasets CSV', fontweight='bold')
    ax1.set_ylabel('Nombre de lignes')
    ax1.grid(axis='y', alpha=0.3)

# Image counts
ax2 = fig.add_subplot(gs[0, 1])
if CLEANED_IMAGES.exists():
    counts = {}
    for split in ['train', 'test']:
        for label in ['benign', 'malignant']:
            img_dir = CLEANED_IMAGES / split / label
            if img_dir.exists():
                count = len(list(img_dir.glob("*.jpg")))
                counts[f"{split}_{label}"] = count
    
    if counts:
        colors = ['#2ecc71' if 'benign' in k else '#e74c3c' for k in counts.keys()]
        ax2.bar(range(len(counts)), counts.values(), color=colors, edgecolor='black')
        ax2.set_xticks(range(len(counts)))
        ax2.set_xticklabels(counts.keys(), rotation=45, ha='right', fontsize=9)
        ax2.set_title('Nombre d\'Images par Cat√©gorie', fontweight='bold')
        ax2.set_ylabel('Nombre d\'images')
        ax2.grid(axis='y', alpha=0.3)

# Distribution globale pathology
ax3 = fig.add_subplot(gs[0, 2])
if all_data:
    all_pathology = pd.concat([df['pathology'] for df in all_data.values() if 'pathology' in df.columns])
    counts = all_pathology.value_counts()
    colors = ['#2ecc71' if 'benign' in str(x).lower() else '#e74c3c' for x in counts.index]
    
    wedges, texts, autotexts = ax3.pie(counts.values, labels=counts.index, autopct='%1.1f%%',
                                        colors=colors, startangle=90,
                                        textprops={'fontweight': 'bold'})
    ax3.set_title('Distribution Globale Pathology', fontweight='bold')

# Compl√©tude vs Taille
ax4 = fig.add_subplot(gs[1, :])
if all_data:
    dataset_names = []
    dataset_sizes = []
    dataset_completeness = []
    
    for name, df in all_data.items():
        dataset_names.append(name[:20])
        dataset_sizes.append(len(df))
        missing_pct = (df.isnull().sum().sum() / (len(df) * df.shape[1])) * 100
        dataset_completeness.append(100 - missing_pct)
    
    x = np.arange(len(dataset_names))
    width = 0.35
    
    ax4_twin = ax4.twinx()
    
    bars1 = ax4.bar(x - width/2, dataset_sizes, width, label='Taille', color='steelblue', edgecolor='black')
    bars2 = ax4_twin.bar(x + width/2, dataset_completeness, width, label='Compl√©tude (%)', 
                        color='lightcoral', edgecolor='black')
    
    ax4.set_xlabel('Dataset', fontweight='bold')
    ax4.set_ylabel('Nombre de lignes', fontweight='bold', color='steelblue')
    ax4_twin.set_ylabel('Compl√©tude (%)', fontweight='bold', color='lightcoral')
    ax4.set_title('Taille vs Compl√©tude des Datasets', fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels(dataset_names, rotation=45, ha='right')
    ax4.legend(loc='upper left')
    ax4_twin.legend(loc='upper right')
    ax4.grid(axis='y', alpha=0.3)

fig.suptitle('Tableau de Bord Multimodal - CSV + Images', fontsize=18, fontweight='bold', y=0.98)
plt.tight_layout()
fig_path = FIGURES_DIR / '06_dashboard_multimodal.png'
plt.savefig(fig_path, dpi=300, bbox_inches='tight')
visualizations_created.append(str(fig_path))
print(f"   ‚úÖ {fig_path.name}")
plt.close()

# ==========================================
# 4. RAPPORT AVEC IMAGES
# ==========================================

print(f"\nüìù Partie 4: G√©n√©ration rapport avec images")
print("-" * 80)

# Cr√©er le rapport
rapport = f"""# RAPPORT D'EXPLORATION MULTIMODALE
## Donn√©es CSV + Images - Cancer du Sein

**Date** : {datetime.now().strftime('%d/%m/%Y')}  
**Auteur** : TIA Ange Jules-Rihem ben Maouia

---

## 1. Introduction

Ce rapport pr√©sente une exploration compl√®te des donn√©es multimodales combinant :
- **Donn√©es tabulaires (CSV)** : M√©tadonn√©es cliniques et diagnostics
- **Donn√©es images** : Mammographies pr√©trait√©es

---

## 2. Donn√©es CSV

### 2.1 Distribution des Classes

![Distribution des Classes](../presentation/figures/01_distribution_classes.png)

**Observations** :
- Datasets relativement √©quilibr√©s entre benign et malignant
- Importante pour √©viter le biais de classe dans les mod√®les

### 2.2 Qualit√© des Donn√©es

![Qualit√© des Datasets](../presentation/figures/02_qualite_datasets.png)

**M√©triques de qualit√©** :
"""

# Ajouter statistiques
if all_data:
    for name, df in all_data.items():
        missing_pct = (df.isnull().sum().sum() / (len(df) * df.shape[1])) * 100
        completeness = 100 - missing_pct
        rapport += f"- **{name}** : {completeness:.2f}% de compl√©tude ({len(df)} lignes)\n"

rapport += f"""

**R√©sultat** : Qualit√© excellente (> 99% de compl√©tude pour tous les datasets)

### 2.3 Corr√©lations

![Matrice de Corr√©lation](../presentation/figures/03_correlation_matrix.png)

**Analyse** :
- Identification des variables fortement corr√©l√©es
- Utile pour feature selection et r√©duction de dimensionnalit√©

---

## 3. Donn√©es Images

### 3.1 √âchantillon d'Images

![Mosa√Øque d'images](../presentation/figures/04_mosaique_images.png)

**Caract√©ristiques** :
- Taille normalis√©e : 224√ó224 pixels
- Niveaux de gris
- Pr√©traitements appliqu√©s : CLAHE, d√©bruitage, normalisation

### 3.2 Distribution d'Intensit√©

![Histogrammes d'intensit√©](../presentation/figures/05_histogrammes_intensite.png)

**Observations** :
- Les images benignes et malignes ont des distributions d'intensit√© similaires
- N√©cessite des features plus avanc√©es pour discrimination

---

## 4. Fusion Multimodale

### 4.1 Dashboard Multimodal

![Dashboard Multimodal](../presentation/figures/06_dashboard_multimodal.png)

**Vue d'ensemble** :
- Coh√©rence entre donn√©es CSV et images
- Pr√©paration compl√®te pour mod√©lisation multimodale

---

## 5. Utilit√© des Fichiers JSON

### 5.1 R√¥le et Avantages

Les fichiers JSON jouent un r√¥le **crucial** dans ce projet :

#### üìä **Tra√ßabilit√©**
```json
{{
  "timestamp": "2025-12-01T23:16:03",
  "operation": "nettoyage_csv",
  "rows_before": 1546,
  "rows_after": 1545
}}
```
- Enregistrement de chaque transformation
- Auditabilit√© compl√®te du pipeline
- Reproductibilit√© garantie

#### üîÑ **Reproductibilit√©**
- Configuration exacte du pipeline
- Param√®tres utilis√©s √† chaque √©tape
- Permet de recr√©er les r√©sultats

#### üìà **M√©tadonn√©es Structur√©es**
- Features extraites des CSV
- Statistiques des images
- Informations de fusion

#### ü§ñ **Interop√©rabilit√©**
- Format standard lisible par Python, R, JavaScript
- Facilite l'√©change de donn√©es
- Compatible avec APIs et web services

### 5.2 Exemples d'Utilisation

**1. Chargement des features** :
```python
import json
with open('data/features/csv/dataset_features.json') as f:
    features = json.load(f)
completeness = features['completeness']
```

**2. Analyse des logs** :
```python
with open('data/logs/cleaning_log.json') as f:
    log = json.load(f)
print(f"Op√©rations: {{len(log['operations'])}}")
```

**3. Comparaison avant/apr√®s** :
```python
# Charger rapport final
with open('reports/RAPPORT_FINAL_PROJET.json') as f:
    rapport = json.load(f)
print(f"Compl√©tude: {{rapport['donnees_csv']['completude_moyenne']}}%")
```

### 5.3 Structure Typique

```json
{{
  "metadata": {{
    "date": "2025-12-02",
    "author": "TIA Ange Jules-Rihem"
  }},
  "data_quality": {{
    "completeness": 99.05,
    "duplicates": 0
  }},
  "transformations": [
    {{
      "step": "normalisation",
      "details": "..."
    }}
  ]
}}
```

**Avantages** :
- ‚úÖ Lisible par humains ET machines
- ‚úÖ Hi√©rarchique et structur√©
- ‚úÖ L√©ger et rapide
- ‚úÖ Standard universel

---

## 6. Conclusion

Ce projet d√©montre une approche compl√®te de pr√©paration de donn√©es multimodales :

- ‚úÖ **CSV** : 4 datasets, 3,564 lignes, 99.05% compl√©tude
- ‚úÖ **Images** : 40 images pr√©trait√©es, normalis√©es
- ‚úÖ **Fusion** : Dataset unifi√© pr√™t pour ML
- ‚úÖ **Tra√ßabilit√©** : Logs JSON complets
- ‚úÖ **Visualisations** : 6 graphiques analytiques

**Pr√™t pour** :
- Entra√Ænement de mod√®les classiques (CSV seul)
- Deep learning (images seules)
- Mod√®les multimodaux (CSV + images)

---

**Visualisations g√©n√©r√©es** : {len(visualizations_created)}  
**Rapport g√©n√©r√© le** : {datetime.now().strftime('%d/%m/%Y √† %H:%M')}
"""

# Sauvegarder
rapport_path = REPORTS_DIR / 'RAPPORT_EXPLORATION_MULTIMODALE.md'
with open(rapport_path, 'w', encoding='utf-8') as f:
    f.write(rapport)

print(f"   ‚úÖ {rapport_path}")

# ==========================================
# 5. R√âSUM√â
# ==========================================

print(f"\n{'='*80}")
print(f"‚ú® VISUALISATIONS G√âN√âR√âES AVEC SUCC√àS!")
print(f"{'='*80}\n")

print(f"üìä Visualisations cr√©√©es ({len(visualizations_created)}) :")
for viz_path in visualizations_created:
    print(f"   ‚úÖ {Path(viz_path).name}")

print(f"\nüìÑ Rapport : {rapport_path}")
print(f"\nüöÄ Prochaine √©tape : Int√©grer dans Streamlit")
print(f"{'='*80}\n")

# Sauvegarder liste des visualisations
viz_manifest = {
    'timestamp': datetime.now().isoformat(),
    'total_visualizations': len(visualizations_created),
    'visualizations': [
        {
            'path': viz,
            'name': Path(viz).name,
            'type': 'PNG'
        }
        for viz in visualizations_created
    ]
}

with open(FIGURES_DIR / 'visualizations_manifest.json', 'w') as f:
    json.dump(viz_manifest, f, indent=4)
